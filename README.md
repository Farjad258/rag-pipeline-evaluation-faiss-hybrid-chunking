# Evaluating RAG Pipelines with FAISS and Hybrid Retrieval (Fixed vs Sentence Chunking)

This repository contains a **reproducible research implementation** of a Retrieval-Augmented Generation (RAG)
pipeline evaluated on the **20 Newsgroups** dataset. It compares:

- **Retrieval:** FAISS (dense) vs **Hybrid** retrieval (FAISS + BM25)
- **Chunking:** fixed-length vs sentence-based chunking
- **Metrics:** precision, recall, hallucination rate, and answer length

This code accompanies an academic manuscript intended for **IEEE / Springer** submission and is structured
as a paper-companion repository.

---

## Repository Structure

- `notebooks/` ‚Äî Main executable notebook (end-to-end pipeline)
- `src/` ‚Äî (Optional) Future refactor into Python modules
- `experiments/` ‚Äî (Optional) Experiment runner scripts
- `figures/` ‚Äî Publication-quality plots for the paper
- `data/` ‚Äî Outputs generated by the notebook (CSV results, embeddings, chunk files)

---

## Method Summary (What the notebook does)

The notebook implements the following pipeline:

1. **Dataset**: loads 20 Newsgroups via scikit-learn (`fetch_20newsgroups`)
2. **Chunking**:
   - Fixed-length chunking
   - Sentence-based chunking (regex-based; no NLTK dependency)
   Chunks are saved under `data/chunks/`
3. **Embeddings**: SentenceTransformer `all-MiniLM-L6-v2` ‚Üí saved to `data/embeddings.pkl`
4. **Retrieval**:
   - FAISS index (`IndexFlatL2`)
   - BM25 index (`rank_bm25`)
   - Hybrid retrieval = union of FAISS + BM25 top-k results (deduplicated)
5. **Generation**: `transformers` text-generation pipeline using `EleutherAI/gpt-neo-125M`
6. **Evaluation**:
   - overlap-based **precision/recall**
   - **hallucination rate** (tokens not present in retrieved context)
   - **answer length**
   Outputs:
   - `data/rag_evaluation_results.csv`
   - `data/rag_experiment_results.csv`
7. **Plots**: matplotlib/seaborn bar plots for paper-ready visualization

---

## Quickstart (Reproduce Results)

### 1) Install dependencies
```bash
**pip install -r requirements.txt**
If faiss-cpu fails on Windows, install it via conda:
**conda install -c conda-forge faiss-cpu**

### 2) Run the Notebook
Open Jupyter and execute the notebook end-to-end:
**jupyter notebook notebooks/RAG_Project.ipynb**

### 3) Expected outputs

After a successful run, the following artifacts will be generated under the data/ directory:

**data/chunks/** ‚Äî fixed-length and sentence-based text chunks
**data/embeddings.pkl** ‚Äî document embeddings used for retrieval
**data/rag_evaluation_results.csv** ‚Äî per-query evaluation metrics
**data/rag_experiment_results.csv** ‚Äî aggregated experimental results

These outputs are used to generate the tables and figures reported in the manuscript.


### Reproducibility Notes

The dataset is loaded automatically using **sklearn.datasets.fetch_20newsgroups**.
Pretrained models for SentenceTransformers and GPT-Neo are downloaded automatically on first run.
Minor numerical variations may occur across environments due to model initialization and library versions


### Citation

If you use this code in academic work, please cite it.
GitHub also provides a ‚ÄúCite this repository‚Äù option via the included CITATION.cff file.

@article{danish2026rag,
  title={Evaluating Retrieval-Augmented Generation (RAG) Pipelines Using FAISS and Hybrid Retrieval with Fixed vs. Sentence-Based Chunking},
  author={Danish, Farjad},
  year={2026},
  note={Code available on GitHub}
}

### Author

Farjad Danish
Applied AI Researcher
üìß farjadkhan258@gmail.com





