# Evaluating Retrieval-Augmented Generation Pipelines with FAISS and Hybrid Retrieval

This repository contains a **reproducible research implementation** of a Retrieval-Augmented Generation (RAG)
pipeline evaluated on the **20 Newsgroups** dataset. It compares:

- **Retrieval:** FAISS (dense) vs **Hybrid** retrieval (FAISS + BM25)
- **Chunking:** fixed-length vs sentence-based chunking
- **Metrics:** token-level F1, ROUGE-L, hallucination token rate, and answer length

This code accompanies an academic manuscript intended for **IEEE** submission and is structured
as a paper-companion repository.

---

## Repository Structure

- `notebooks/` ‚Äî Main executable notebook (end-to-end pipeline)
- `src/` ‚Äî Future refactor into Python modules
- `experiments/` ‚Äî Experiment runner scripts
- `figures/` ‚Äî Publication-quality plots for the paper
- `data/` ‚Äî Outputs generated by the notebook (CSV results, embeddings, chunk files)

---

## Method Summary (What the notebook does)

The notebook implements the following pipeline:

1. **Dataset**: loads 20 Newsgroups via scikit-learn (`fetch_20newsgroups`)
2. **Chunking**:
   - Fixed-length chunking
   - Sentence-based chunking (regex-based; no NLTK dependency)
   Chunks are saved under `data/chunks/`
3. **Embeddings**: SentenceTransformer `all-MiniLM-L6-v2` ‚Üí saved to `data/embeddings.pkl`
4. **Retrieval**:
   - FAISS index (`IndexFlatIP`) with cosine similarity via normalized embeddings
   - BM25 index (`rank_bm25`)
   - Hybrid retrieval using Reciprocal Rank Fusion (RRF) over FAISS and BM25 rank positions (k=60)
5. **Generation**: `transformers` text-generation pipeline using `EleutherAI/gpt-neo-125M`
6. **Evaluation**:
   - token-overlap‚Äìbased coverage metrics (Token F1 and ROUGE-L)
   - **hallucination rate** (tokens not present in retrieved context)
   - **answer length**
   Outputs:
   - `outputs/detail_*.csv` ‚Äî per-query evaluation results
   - `outputs/summary_*.csv` ‚Äî configuration-level metric summaries
   - `outputs/Table_I.csv` ‚Äî publication-ready results table
7. **Plots**: matplotlib/seaborn bar plots for paper-ready visualization

---

## Quickstart (Reproduce Results)

### 1) Install dependencies
```bash
pip install -r requirements.txt
```
**Note:** If faiss-cpu fails to install via pip (common on Windows), install it via conda:
```bash
conda install -c conda-forge faiss-cpu
```

### 2) Run the Notebook
Open Jupyter and execute the notebook end-to-end:
```bash
jupyter notebook notebooks/RAG_Project.ipynb
```

### 3) Expected outputs
After a successful run, the following artifacts will be generated under the data/ directory:

- `data/chunks/` ‚Äî fixed-length and sentence-based text chunks
- `data/embeddings.pkl` ‚Äî document embeddings used for retrieval
- `data/rag_evaluation_results.csv` ‚Äî per-query evaluation metrics
- `data/rag_experiment_results.csv` ‚Äî aggregated experimental results

These outputs are used to generate the tables and figures reported in the manuscript.


## Reproducibility Notes

- The dataset is loaded automatically using `sklearn.datasets.fetch_20newsgroups`.
- Pretrained models for SentenceTransformers and GPT-Neo are downloaded automatically on first run.
- Minor numerical variations may occur across environments due to model initialization and library versions.


## Citation

If you use this code in academic work, please cite it.
GitHub also provides a ‚ÄúCite this repository‚Äù option via the included CITATION.cff file.

```bibtex
@article{danish2026rag,
  title={Evaluating Retrieval-Augmented Generation Pipelines with FAISS and Hybrid Retrieval},
  author={Danish, Farjad},
  year={2026},
  note={Code available on GitHub}
}
```

## Author

**Farjad Danish**  
Independent Researcher (Applied Artificial Intelligence)  
üìß farjadkhan258@gmail.com

## License
This project is released under the MIT License. See the `LICENSE` file for details.

## Paper & Reproducibility
Code and results are released as **v1.0.0** for reproducibility (see GitHub Releases).







